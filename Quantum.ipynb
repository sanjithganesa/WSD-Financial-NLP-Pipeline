{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1QrSZYoDkwDf_yD81BKpygEDlGLxS53h6",
      "authorship_tag": "ABX9TyPS4f2OqaiI+Tx9+07TzrF5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6fc2fadd0a444285a671b4d3275c9eb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db4315fef83a41548c0de93b0c503661",
              "IPY_MODEL_7599cb968523463ba49597c19cd2af5e",
              "IPY_MODEL_e6225bca48e54d1eb8517deb3240c5e7"
            ],
            "layout": "IPY_MODEL_9f1f1af1ac0943839ba0df1eebe2bd18"
          }
        },
        "db4315fef83a41548c0de93b0c503661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e714ff6479749cf89b8fc7cc469c0ab",
            "placeholder": "​",
            "style": "IPY_MODEL_f5ea84247a55443983c1ecf68e9c7dd5",
            "value": "Batches: 100%"
          }
        },
        "7599cb968523463ba49597c19cd2af5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b04e91fe68f947f283ba1c16a76a04c4",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5624a41f47284686942f27dc7adfea3e",
            "value": 3
          }
        },
        "e6225bca48e54d1eb8517deb3240c5e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3df03846d35c45079410e62a8c30e0f8",
            "placeholder": "​",
            "style": "IPY_MODEL_c60a7deb995a48a59c5ac397d86d8faa",
            "value": " 3/3 [00:07&lt;00:00,  2.06s/it]"
          }
        },
        "9f1f1af1ac0943839ba0df1eebe2bd18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e714ff6479749cf89b8fc7cc469c0ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5ea84247a55443983c1ecf68e9c7dd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b04e91fe68f947f283ba1c16a76a04c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5624a41f47284686942f27dc7adfea3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3df03846d35c45079410e62a8c30e0f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c60a7deb995a48a59c5ac397d86d8faa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjithganesa/WSD-Financial-NLP-Pipeline/blob/main/Quantum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vhAAqdS27qHW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500,
          "referenced_widgets": [
            "6fc2fadd0a444285a671b4d3275c9eb8",
            "db4315fef83a41548c0de93b0c503661",
            "7599cb968523463ba49597c19cd2af5e",
            "e6225bca48e54d1eb8517deb3240c5e7",
            "9f1f1af1ac0943839ba0df1eebe2bd18",
            "2e714ff6479749cf89b8fc7cc469c0ab",
            "f5ea84247a55443983c1ecf68e9c7dd5",
            "b04e91fe68f947f283ba1c16a76a04c4",
            "5624a41f47284686942f27dc7adfea3e",
            "3df03846d35c45079410e62a8c30e0f8",
            "c60a7deb995a48a59c5ac397d86d8faa"
          ]
        },
        "outputId": "9b2f5db1-5d2a-4941-f001-70b907a1418f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DATA] Loading 20 Newsgroups subset...\n",
            "[DATA] 80 samples loaded.\n",
            "[EMB] Getting embeddings...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6fc2fadd0a444285a671b4d3275c9eb8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PCA] Reducing embeddings to 4 dims (for 4 qubits)\n",
            "[Q] Building quantum classifier...\n",
            "[TRAIN] Starting hybrid training...\n",
            "Return from COBYLA because the objective function has been evaluated MAXFUN times.\n",
            "Number of function values = 15   Least value of F = 0.678279728065877\n",
            "The corresponding X is:\n",
            "[ 0.04967142 -0.01382643  1.06476885  1.15230299 -0.02341534 -0.0234137\n",
            "  1.15792128  0.07674347]\n",
            "\n",
            "[RESULT] Val Acc=0.4375  Val F1=0.4353\n",
            "Sample 0: label=0 prob=0.459 pred=0\n",
            "Sample 1: label=1 prob=0.525 pred=1\n",
            "Sample 2: label=1 prob=0.889 pred=1\n",
            "Sample 3: label=1 prob=0.496 pred=0\n",
            "Sample 4: label=0 prob=0.502 pred=1\n",
            "Sample 5: label=0 prob=0.477 pred=0\n",
            "Sample 6: label=1 prob=0.455 pred=0\n",
            "Sample 7: label=0 prob=0.496 pred=0\n",
            "{'theta': array([ 0.04967142, -0.01382643,  1.06476885,  1.15230299, -0.02341534,\n",
            "       -0.0234137 ,  1.15792128,  0.07674347]), 'val_acc': 0.4375, 'val_f1': 0.43529411764705883, 'val_probs': array([0.45898438, 0.52539062, 0.88867188, 0.49609375, 0.50195312,\n",
            "       0.4765625 , 0.45507812, 0.49609375, 0.59960938, 0.5546875 ,\n",
            "       0.64453125, 0.61328125, 0.49804688, 0.4765625 , 0.54882812,\n",
            "       0.8828125 ])}\n"
          ]
        }
      ],
      "source": [
        "# Colab friendly\n",
        "\n",
        "import os\n",
        "import re\n",
        "from pathlib import Path\n",
        "from typing import List, Optional, Tuple, Dict, Any\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Optional SBERT\n",
        "try:\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    SBERT_AVAILABLE = True\n",
        "except Exception:\n",
        "    SBERT_AVAILABLE = False\n",
        "\n",
        "# Qiskit imports\n",
        "QISKIT_AVAILABLE = False\n",
        "AER_AVAILABLE = False\n",
        "USE_STATEVECTOR = False\n",
        "try:\n",
        "    from qiskit import QuantumCircuit, transpile\n",
        "    from qiskit.circuit import ParameterVector\n",
        "    try:\n",
        "        from qiskit_aer import AerSimulator\n",
        "        AER_AVAILABLE = True\n",
        "    except Exception:\n",
        "        try:\n",
        "            from qiskit.providers.aer import AerSimulator\n",
        "            AER_AVAILABLE = True\n",
        "        except Exception:\n",
        "            AER_AVAILABLE = False\n",
        "    from qiskit.quantum_info import Statevector\n",
        "    QISKIT_AVAILABLE = True\n",
        "    if not AER_AVAILABLE:\n",
        "        USE_STATEVECTOR = True\n",
        "except Exception as e:\n",
        "    QISKIT_AVAILABLE = False\n",
        "    print(\"[WARN] Qiskit not available:\", e)\n",
        "\n",
        "if not QISKIT_AVAILABLE:\n",
        "    raise SystemExit(\"Qiskit not available. Install qiskit and restart runtime.\")\n",
        "\n",
        "# -------------------------\n",
        "# Utilities\n",
        "# -------------------------\n",
        "def clean_text(s: str) -> str:\n",
        "    if s is None:\n",
        "        return \"\"\n",
        "    s = re.sub(r\"\\s+\", \" \", s.replace(\"\\n\", \" \").replace(\"\\r\", \" \")).strip()\n",
        "    s = re.sub(r\"http\\S+\", \"\", s)\n",
        "    s = re.sub(r\"[^A-Za-z0-9\\s\\.\\,\\-\\$%€£:;()\\/\\#\\@]\", \" \", s)\n",
        "    s = re.sub(r\"\\s{2,}\", \" \", s)\n",
        "    return s.strip()\n",
        "\n",
        "# -------------------------\n",
        "# Embedding helpers\n",
        "# -------------------------\n",
        "def get_sentence_embeddings(texts: List[str], model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\") -> np.ndarray:\n",
        "    if SBERT_AVAILABLE:\n",
        "        try:\n",
        "            model = SentenceTransformer(model_name)\n",
        "            vecs = model.encode(texts, convert_to_numpy=True, show_progress_bar=True)\n",
        "            return np.array(vecs, dtype=np.float32)\n",
        "        except Exception as e:\n",
        "            print(\"[WARN] SBERT encoding failed:\", e)\n",
        "    tf = TfidfVectorizer(max_features=512)\n",
        "    X = tf.fit_transform(texts).toarray()\n",
        "    return X.astype(np.float32)\n",
        "\n",
        "# -------------------------\n",
        "# Quantum circuit utilities\n",
        "# -------------------------\n",
        "def build_feature_map(n_qubits: int, feature_angles: np.ndarray) -> QuantumCircuit:\n",
        "    qc = QuantumCircuit(n_qubits)\n",
        "    for i in range(n_qubits):\n",
        "        qc.ry(float(feature_angles[i]), i)\n",
        "    return qc\n",
        "\n",
        "def build_variational_circuit(n_qubits: int, reps: int = 2) -> Tuple[QuantumCircuit, ParameterVector]:\n",
        "    param_len = n_qubits * reps * 2\n",
        "    params = ParameterVector(\"theta\", length=param_len)\n",
        "    qc = QuantumCircuit(n_qubits)\n",
        "    idx = 0\n",
        "    for r in range(reps):\n",
        "        for q in range(n_qubits):\n",
        "            qc.ry(params[idx], q); idx += 1\n",
        "            qc.rz(params[idx], q); idx += 1\n",
        "        for q in range(n_qubits - 1):\n",
        "            qc.cx(q, q + 1)\n",
        "        qc.cx(n_qubits - 1, 0)\n",
        "    return qc, params\n",
        "\n",
        "def expectation_from_counts(counts: Dict[str, int]) -> float:\n",
        "    total = sum(counts.values()) if len(counts) else 1\n",
        "    prob0 = 0.0\n",
        "    for bitstr, c in counts.items():\n",
        "        if len(bitstr) == 0:\n",
        "            continue\n",
        "        if bitstr[-1] == \"0\":\n",
        "            prob0 += c\n",
        "    return prob0 / total\n",
        "\n",
        "# -------------------------\n",
        "# Simulator wrapper\n",
        "# -------------------------\n",
        "class SimulatorRunner:\n",
        "    def __init__(self, n_qubits: int, shots: int = 512):\n",
        "        self.n_qubits = n_qubits\n",
        "        self.shots = shots\n",
        "        self.use_aer = AER_AVAILABLE\n",
        "        if self.use_aer:\n",
        "            self.backend = AerSimulator()\n",
        "        else:\n",
        "            self.backend = None\n",
        "\n",
        "    def run_and_get_prob0(self, qc: QuantumCircuit) -> float:\n",
        "        if self.use_aer:\n",
        "            tqc = transpile(qc, self.backend)\n",
        "            job = self.backend.run(tqc, shots=self.shots)\n",
        "            result = job.result()\n",
        "            counts = result.get_counts()\n",
        "            return expectation_from_counts(counts)\n",
        "        else:\n",
        "            qc_no_meas = qc.remove_final_measurements(inplace=False)\n",
        "            sv = Statevector.from_instruction(qc_no_meas)\n",
        "            prob0 = sum(p for bitstr, p in sv.probabilities_dict().items() if bitstr[-1]=='0')\n",
        "            return float(prob0)\n",
        "\n",
        "# -------------------------\n",
        "# Quantum classifier\n",
        "# -------------------------\n",
        "class QuantumClassifier:\n",
        "    def __init__(self, n_qubits=6, reps=2, shots=512):\n",
        "        self.n_qubits = n_qubits\n",
        "        self.reps = reps\n",
        "        self.shots = shots\n",
        "        self.vqc_template, self.params = build_variational_circuit(n_qubits, reps)\n",
        "        self.runner = SimulatorRunner(n_qubits, shots)\n",
        "        try:\n",
        "            from qiskit.utils import algorithm_globals\n",
        "            algorithm_globals.random_seed = 42\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    def _construct_circuit(self, angles, theta_values):\n",
        "        fmap = build_feature_map(self.n_qubits, angles)\n",
        "        qc = QuantumCircuit(self.n_qubits, self.n_qubits)\n",
        "        qc = qc.compose(fmap)\n",
        "        qc = qc.compose(self.vqc_template)\n",
        "        bind_dict = {self.params[i]: float(theta_values[i]) for i in range(len(self.params))}\n",
        "        try:\n",
        "          # newer Qiskit\n",
        "          qc = qc.bind_parameters(bind_dict)\n",
        "        except AttributeError:\n",
        "          # older Qiskit\n",
        "          qc = qc.assign_parameters(bind_dict)\n",
        "\n",
        "        qc.measure(range(self.n_qubits), range(self.n_qubits))\n",
        "        return qc\n",
        "\n",
        "    def predict_proba_single(self, angles, theta_values):\n",
        "        qc = self._construct_circuit(angles, theta_values)\n",
        "        return self.runner.run_and_get_prob0(qc)\n",
        "\n",
        "    def batch_predict_proba(self, angles_batch, theta_values):\n",
        "        return np.array([self.predict_proba_single(angles, theta_values) for angles in angles_batch])\n",
        "\n",
        "# -------------------------\n",
        "# Loss + training\n",
        "# -------------------------\n",
        "def binary_cross_entropy(probs, labels, eps=1e-9):\n",
        "    probs = np.clip(probs, eps, 1-eps)\n",
        "    labels = labels.astype(np.float32)\n",
        "    return -np.mean(labels*np.log(probs) + (1-labels)*np.log(1-probs))\n",
        "\n",
        "def train_quantum_classifier(qc, X_train, y_train, X_val, y_val, epochs=30, optimizer_name=\"COBYLA\"):\n",
        "    from scipy.optimize import minimize\n",
        "    n_params = len(qc.params)\n",
        "    theta0 = np.random.RandomState(42).normal(scale=0.1, size=n_params)\n",
        "    def objective(theta):\n",
        "        probs = qc.batch_predict_proba(X_train, theta)\n",
        "        return float(binary_cross_entropy(probs, y_train))\n",
        "    method = \"COBYLA\" if optimizer_name.upper()==\"COBYLA\" else \"Powell\"\n",
        "    res = minimize(objective, theta0, method=method, options={\"maxiter\":epochs, \"disp\":True})\n",
        "    theta_opt = res.x\n",
        "    val_probs = qc.batch_predict_proba(X_val, theta_opt)\n",
        "    val_preds = (val_probs>=0.5).astype(int)\n",
        "    acc = accuracy_score(y_val, val_preds)\n",
        "    f1 = f1_score(y_val, val_preds, average=\"macro\")\n",
        "    return theta_opt, acc, f1, val_probs\n",
        "\n",
        "# -------------------------\n",
        "# Helper functions\n",
        "# -------------------------\n",
        "def angles_from_features(X, n_qubits):\n",
        "    N, d = X.shape\n",
        "    if d > n_qubits:\n",
        "        X = X[:, :n_qubits]\n",
        "        d = n_qubits\n",
        "    angles = np.zeros((N, n_qubits), dtype=float)\n",
        "    mins = X.min(axis=0, keepdims=True)\n",
        "    maxs = X.max(axis=0, keepdims=True)\n",
        "    denom = maxs - mins\n",
        "    denom[denom==0] = 1.0\n",
        "    X_norm = (X - mins)/denom\n",
        "    angles[:, :d] = (X_norm - 0.5)*np.pi\n",
        "    return angles\n",
        "\n",
        "# -------------------------\n",
        "# Demo runner\n",
        "# -------------------------\n",
        "def demo_quantum_wsd_pipeline(n_qubits=6, n_pca=None, n_samples=120, epochs=30, reps=1):\n",
        "    print(\"[DATA] Loading 20 Newsgroups subset...\")\n",
        "    categories = ['rec.sport.hockey', 'sci.space']\n",
        "    dataset = fetch_20newsgroups(subset='train', categories=categories, remove=('headers','footers','quotes'))\n",
        "    texts = [clean_text(t) for t in dataset.data[:n_samples]]\n",
        "    labels = np.array(dataset.target[:n_samples])\n",
        "\n",
        "    print(f\"[DATA] {len(texts)} samples loaded.\")\n",
        "\n",
        "    print(\"[EMB] Getting embeddings...\")\n",
        "    emb = get_sentence_embeddings(texts)\n",
        "\n",
        "    if n_pca is None:\n",
        "        n_pca = min(emb.shape[1], n_qubits)\n",
        "    n_pca = min(n_pca, n_qubits)\n",
        "\n",
        "    print(f\"[PCA] Reducing embeddings to {n_pca} dims (for {n_qubits} qubits)\")\n",
        "    pca = PCA(n_components=n_pca)\n",
        "    X_reduced = pca.fit_transform(emb)\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_reduced, labels, test_size=0.2, random_state=42, stratify=labels)\n",
        "    X_angles_train = angles_from_features(X_train, n_qubits)\n",
        "    X_angles_val = angles_from_features(X_val, n_qubits)\n",
        "\n",
        "    print(\"[Q] Building quantum classifier...\")\n",
        "    qc = QuantumClassifier(n_qubits=n_qubits, reps=reps, shots=512)\n",
        "\n",
        "    print(\"[TRAIN] Starting hybrid training...\")\n",
        "    theta_opt, acc_val, f1_val, val_probs = train_quantum_classifier(qc, X_angles_train, y_train, X_angles_val, y_val, epochs=epochs)\n",
        "\n",
        "    print(f\"[RESULT] Val Acc={acc_val:.4f}  Val F1={f1_val:.4f}\")\n",
        "    preds = (val_probs >= 0.5).astype(int)\n",
        "    for i in range(min(8, len(preds))):\n",
        "        print(f\"Sample {i}: label={y_val[i]} prob={val_probs[i]:.3f} pred={preds[i]}\")\n",
        "\n",
        "    return {\"theta\": theta_opt, \"val_acc\": acc_val, \"val_f1\": f1_val, \"val_probs\": val_probs}\n",
        "\n",
        "# -------------------------\n",
        "# Example usage\n",
        "# -------------------------\n",
        "result = demo_quantum_wsd_pipeline(n_qubits=4, n_samples=80, epochs=15, reps=1)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab install cell (run this first)\n",
        "!pip install --quiet qiskit qiskit-aer scipy sentence-transformers tqdm\n",
        "# If qiskit-aer fails to build on Python 3.12 this will still install qiskit core; code falls back to Statevector.\n"
      ],
      "metadata": {
        "id": "wod4r09w7rr6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a54efd8a-0daf-41ac-fc59-26485d35746d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Download dataset\n",
        "path = kagglehub.dataset_download(\"nltkdata/reuters\")\n",
        "print(\"KaggleHub downloaded to:\", path)\n",
        "\n",
        "# Target folder in Google Drive\n",
        "target_path = \"/content/drive/MyDrive/reuters\"\n",
        "\n",
        "# Copy downloaded dataset into Drive\n",
        "if os.path.exists(target_path):\n",
        "    shutil.rmtree(target_path)\n",
        "\n",
        "shutil.copytree(path, target_path)\n",
        "\n",
        "print(\"Dataset copied to:\", target_path)\n"
      ],
      "metadata": {
        "id": "-UIfwPpO8NAV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e627009b-1438-4ea8-c177-7342e5e38a8b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/nltkdata/reuters?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12.8M/12.8M [00:00<00:00, 14.5MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KaggleHub downloaded to: /root/.cache/kagglehub/datasets/nltkdata/reuters/versions/2\n",
            "Dataset copied to: /content/drive/MyDrive/reuters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import shutil\n",
        "\n",
        "SOURCE_PATH = \"/content/drive/MyDrive/reuters/reuters/reuters/reuters/training\"\n",
        "TARGET_PATH = \"/content/drive/MyDrive/reuters_extracted\"\n",
        "\n",
        "# Reset output folder\n",
        "if os.path.exists(TARGET_PATH):\n",
        "    shutil.rmtree(TARGET_PATH)\n",
        "os.makedirs(TARGET_PATH)\n",
        "\n",
        "def clean_text(t):\n",
        "    return re.sub(r\"\\s+\", \" \", t).strip()\n",
        "\n",
        "for fname in os.listdir(SOURCE_PATH):\n",
        "    if not fname.endswith(\".sgm\"):\n",
        "        continue\n",
        "\n",
        "    with open(os.path.join(SOURCE_PATH, fname), \"r\", encoding=\"latin-1\") as f:\n",
        "        data = f.read()\n",
        "\n",
        "    soup = BeautifulSoup(data, \"html.parser\")\n",
        "    articles = soup.find_all(\"reuters\")\n",
        "\n",
        "    for art in articles:\n",
        "        body = art.find(\"body\")\n",
        "        topics = art.find(\"topics\")\n",
        "\n",
        "        if body is None or topics is None:\n",
        "            continue\n",
        "\n",
        "        labels = [t.text for t in topics.find_all(\"d\")]\n",
        "        if len(labels) == 0:\n",
        "            continue\n",
        "\n",
        "        label = labels[0]\n",
        "        text = clean_text(body.text)\n",
        "\n",
        "        # Create label folder\n",
        "        label_folder = os.path.join(TARGET_PATH, label)\n",
        "        os.makedirs(label_folder, exist_ok=True)\n",
        "\n",
        "        # Save text file\n",
        "        file_id = art[\"newid\"]\n",
        "        with open(os.path.join(label_folder, f\"{file_id}.txt\"), \"w\", encoding=\"utf-8\") as fw:\n",
        "            fw.write(text)\n",
        "\n",
        "print(\"Extraction completed →\", TARGET_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBHFaMKvZDbp",
        "outputId": "33d893bb-0da1-49a7-82ed-a4a063c3fb88"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction completed → /content/drive/MyDrive/reuters_extracted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2R4dVFNweBXB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}